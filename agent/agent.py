# -*- coding: utf-8 -*-
"""
Agent æ ¸å¿ƒæ¨¡å— (agent.py)
========================

æœ¬æ¨¡å—å®žçŽ°äº†è‡ªä¸»ç¼–ç¨‹ Agent çš„æ ¸å¿ƒé€»è¾‘ï¼ŒåŒ…æ‹¬ï¼š
- CodingAgentï¼šé¡¹ç›®ä¸»æ‰§è¡Œç±»
- SimpleAgentExecutorï¼šåŸºç¡€å›žé€€æ‰§è¡Œå™¨
- åˆå§‹åŒ–ã€ä»»åŠ¡æ‰§è¡Œã€çŠ¶æ€æŸ¥è¯¢ä¸Žå¯¹è¯æŽ¥å£

è¯´æ˜Žï¼š
- ä¼˜å…ˆå°è¯•ä½¿ç”¨ LangGraph çš„ `create_react_agent`
- å¦‚æžœ LangGraph ä¸å¯ç”¨æˆ–åˆå§‹åŒ–å¤±è´¥ï¼Œè‡ªåŠ¨å›žé€€åˆ°ç®€å•æ‰§è¡Œå™¨
"""

import os
import sys
import time
from datetime import datetime
from typing import Any, Callable, Dict, List, Optional

from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI

try:
    from langgraph.prebuilt import create_react_agent

    LANGGRAPH_AVAILABLE = True
except ImportError:
    LANGGRAPH_AVAILABLE = False

# é¡¹ç›®å†…éƒ¨å¯¼å…¥
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config import Config, set_project_dir
from .git_helper import GitHelper, format_commits_for_prompt
from .progress import Feature, ProgressManager
from .prompts import get_system_prompt, loader as prompt_loader
from .tools import get_all_tools


class SimpleAgentExecutor:
    """
    ç®€æ˜“ Agent æ‰§è¡Œå™¨ã€‚

    è¯¥æ‰§è¡Œå™¨ä¸åšå·¥å…·è§„åˆ’ï¼Œä»…æŠŠç³»ç»Ÿæç¤ºè¯ã€åŽ†å²æ¶ˆæ¯å’Œç”¨æˆ·è¾“å…¥
    å‘é€ç»™ LLMï¼Œä½œä¸º LangGraph ä¸å¯ç”¨æ—¶çš„å›žé€€æ–¹æ¡ˆã€‚
    """

    def __init__(self, llm: ChatOpenAI, tools: List[Any]):
        """åˆå§‹åŒ–å›žé€€æ‰§è¡Œå™¨ã€‚"""
        self.llm = llm
        self.tools = tools

    @staticmethod
    def _normalize_chat_history(chat_history: List[Any]) -> List[Any]:
        """å°†å¤šç§åŽ†å²æ¶ˆæ¯æ ¼å¼æ ‡å‡†åŒ–ä¸º LangChain æ¶ˆæ¯å¯¹è±¡åˆ—è¡¨ã€‚"""
        normalized: List[Any] = []
        for item in chat_history or []:
            if isinstance(item, (HumanMessage, AIMessage, SystemMessage)):
                normalized.append(item)
                continue

            if isinstance(item, tuple) and len(item) == 2:
                role, content = item
                role_str = str(role).lower()
                if role_str in {"human", "user"}:
                    normalized.append(HumanMessage(content=str(content)))
                elif role_str in {"ai", "assistant"}:
                    normalized.append(AIMessage(content=str(content)))
                else:
                    normalized.append(SystemMessage(content=str(content)))
                continue

            if isinstance(item, dict):
                role_str = str(item.get("role", "")).lower()
                content = str(item.get("content", ""))
                if role_str in {"human", "user"}:
                    normalized.append(HumanMessage(content=content))
                elif role_str in {"ai", "assistant"}:
                    normalized.append(AIMessage(content=content))
                else:
                    normalized.append(SystemMessage(content=content))

        return normalized

    def invoke(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œä¸€æ¬¡ LLM è°ƒç”¨å¹¶è¿”å›žç»Ÿä¸€çš„è¾“å‡ºç»“æž„ã€‚"""
        input_text = str(inputs.get("input", ""))
        chat_history = self._normalize_chat_history(inputs.get("chat_history", []))

        messages: List[Any] = [SystemMessage(content=get_system_prompt())]
        messages.extend(chat_history)
        messages.append(HumanMessage(content=input_text))

        response = self.llm.invoke(messages)
        content = getattr(response, "content", str(response))
        return {"output": str(content)}


class CodingAgent:
    """
    è‡ªä¸»ç¼–ç¨‹ Agent ä¸»ç±»ã€‚

    ä¸»è¦èŒè´£ï¼š
    - åˆå§‹åŒ–æ¨¡åž‹ã€å·¥å…·ã€è¿›åº¦å’Œ Git ç®¡ç†å™¨
    - åˆå§‹åŒ–é¡¹ç›®ä¸Šä¸‹æ–‡
    - æŒ‰åŠŸèƒ½ç²’åº¦æ‰§è¡Œä»»åŠ¡
    - æä¾›çŠ¶æ€æŸ¥è¯¢ä¸Žå¯¹è¯èƒ½åŠ›
    """

    def __init__(
        self,
        project_dir: str,
        model_name: Optional[str] = None,
        base_url: Optional[str] = None,
        temperature: Optional[float] = None,
    ):
        """åˆå§‹åŒ– CodingAgent åŠå…¶ä¾èµ–ç»„ä»¶ã€‚"""
        self.project_dir = os.path.abspath(project_dir)
        set_project_dir(self.project_dir)
        os.makedirs(self.project_dir, exist_ok=True)

        self.model_name = model_name or Config.MODEL_NAME
        self.base_url = base_url or Config.OLLAMA_BASE_URL
        self.temperature = (
            temperature if temperature is not None else Config.TEMPERATURE
        )

        self.llm: Optional[ChatOpenAI] = None
        self.tools: List[Any] = []
        self.agent_executor: Optional[Any] = None
        self._fallback_executor: Optional[SimpleAgentExecutor] = None
        self._use_langgraph = False

        self._iteration_count = 0
        self._last_action: Optional[str] = None

        self._init_llm()
        self._init_tools()
        self._init_agent()
        self._init_progress_manager()
        self._init_git_helper()

    def _init_llm(self) -> None:
        """åˆå§‹åŒ– ChatOpenAI å®¢æˆ·ç«¯ã€‚"""
        self.llm = ChatOpenAI(
            model=self.model_name,
            base_url=self.base_url,
            api_key="not-needed",
            temperature=self.temperature,
            max_tokens=Config.MAX_TOKENS,
        )

    def _init_tools(self) -> None:
        """åŠ è½½å¯ä¾› Agent è°ƒç”¨çš„å·¥å…·åˆ—è¡¨ã€‚"""
        self.tools = get_all_tools()

    def _init_agent(self) -> None:
        """åˆå§‹åŒ– Agent æ‰§è¡Œå™¨å¹¶æŒ‰å¯ç”¨èƒ½åŠ›é€‰æ‹©è¿è¡Œæ¨¡å¼ã€‚"""
        self._fallback_executor = SimpleAgentExecutor(self.llm, self.tools)

        if not LANGGRAPH_AVAILABLE:
            self.agent_executor = self._fallback_executor
            self._use_langgraph = False
            return

        try:
            graph_or_runnable = create_react_agent(self.llm, self.tools)
            self.agent_executor = graph_or_runnable
            self._use_langgraph = True
        except Exception:
            self.agent_executor = self._fallback_executor
            self._use_langgraph = False

    def _init_progress_manager(self) -> None:
        """åˆå§‹åŒ–é¡¹ç›®è¿›åº¦ç®¡ç†å™¨ã€‚"""
        self.progress_manager = ProgressManager(self.project_dir)

    def _init_git_helper(self) -> None:
        """åˆå§‹åŒ– Git è¾…åŠ©æ“ä½œå™¨ã€‚"""
        self.git_helper = GitHelper(self.project_dir)

    @staticmethod
    def _extract_langgraph_output(result: Any) -> str:
        """ä»Ž LangGraph è°ƒç”¨ç»“æžœä¸­æå–æœ€ç»ˆæ–‡æœ¬è¾“å‡ºã€‚"""
        if result is None:
            return ""

        if isinstance(result, str):
            return result

        if isinstance(result, dict):
            if "output" in result:
                return str(result.get("output", ""))
            messages = result.get("messages", [])
            if isinstance(messages, list) and messages:
                last_msg = messages[-1]
                return str(getattr(last_msg, "content", str(last_msg)))
            return str(result)

        return str(result)

    def _invoke_agent(self, prompt: str, chat_history: Optional[List[Any]] = None) -> Dict[str, Any]:
        """ç»Ÿä¸€å°è£… Agent è°ƒç”¨ï¼Œä¼˜å…ˆ LangGraphï¼Œå¤±è´¥å›žé€€åˆ°ç®€æ˜“æ‰§è¡Œå™¨ã€‚"""
        history = chat_history or []
        self._last_action = "invoke_agent"

        if self._use_langgraph and self.agent_executor is not None:
            try:
                messages: List[Any] = [SystemMessage(content=get_system_prompt())]
                messages.extend(SimpleAgentExecutor._normalize_chat_history(history))
                messages.append(HumanMessage(content=prompt))
                result = self.agent_executor.invoke({"messages": messages})
                return {"output": self._extract_langgraph_output(result)}
            except Exception:
                self._use_langgraph = False

        return self._fallback_executor.invoke(
            {"input": prompt, "chat_history": history}
        )

    def initialize(self, requirements: str, project_name: Optional[str] = None) -> bool:
        """åˆå§‹åŒ–é¡¹ç›®è¿›åº¦æ–‡ä»¶ã€åŸºç¡€åŠŸèƒ½å’Œåˆå§‹ Git æäº¤ã€‚"""
        if project_name is None:
            project_name = os.path.basename(self.project_dir)

        try:
            ok = self.progress_manager.initialize(project_name, requirements)
            if not ok:
                return False

            feature_list = self.progress_manager.load_feature_list(force_reload=True)
            if feature_list and not feature_list.features:
                self.progress_manager.add_feature(
                    feature_id="feat-001",
                    name="é¡¹ç›®åˆå§‹åŒ–ä¸ŽåŸºç¡€ç»“æž„",
                    description=requirements,
                    priority="high",
                )

            init_prompt = prompt_loader.get_initializer_prompt(
                requirements=requirements,
                project_name=project_name,
                project_dir=self.project_dir,
                current_time=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            )
            init_result = self._invoke_agent(init_prompt, [])
            init_output = init_result.get("output", "").strip()
            if init_output:
                self.progress_manager.append_to_progress(
                    "## åˆå§‹åŒ–åˆ†æž\n\n" + init_output
                )

            if not self.git_helper.is_repo():
                self.git_helper.init_repo()

            if self.git_helper.has_changes():
                self.git_helper.commit("chore: é¡¹ç›®åˆå§‹åŒ–")

            return True
        except Exception as exc:
            print(f"[Agent] åˆå§‹åŒ–å¤±è´¥: {exc}")
            return False

    def run(
        self,
        max_iterations: Optional[int] = None,
        on_iteration: Optional[Callable[[int, Dict[str, Any]], None]] = None,
    ) -> Dict[str, Any]:
        """æ‰§è¡Œå•æ¬¡ä»»åŠ¡å¾ªçŽ¯å¹¶å¤„ç†ä¸€ä¸ªå¯æ‰§è¡ŒåŠŸèƒ½ã€‚"""
        _ = max_iterations or Config.MAX_ITERATIONS

        feature_list = self.progress_manager.load_feature_list(force_reload=True)
        if feature_list is None:
            return {"success": False, "error": "æœªæ‰¾åˆ° feature_list.jsonï¼Œè¯·å…ˆæ‰§è¡Œ init"}

        next_feature = self.progress_manager.get_next_feature()
        if next_feature is None:
            stats = self.progress_manager.get_progress_stats()
            if stats.get("completion_rate") == 100:
                return {"success": True, "message": "æ‰€æœ‰åŠŸèƒ½å·²å®Œæˆ"}
            return {"success": False, "error": "æ²¡æœ‰å¯æ‰§è¡Œçš„åŠŸèƒ½ï¼ˆå¯èƒ½è¢«ä¾èµ–é˜»å¡žï¼‰"}

        self.progress_manager.update_feature_status(next_feature.id, "in_progress")

        progress_content = self.progress_manager.load_progress() or ""
        git_history = format_commits_for_prompt(self.git_helper.get_recent_commits(5))
        init_sh_path = os.path.join(self.project_dir, "init.sh")
        init_sh_content = ""
        if os.path.exists(init_sh_path):
            try:
                with open(init_sh_path, "r", encoding="utf-8") as file_obj:
                    init_sh_content = file_obj.read()
            except Exception:
                init_sh_content = ""

        session_context = self._build_session_context(
            progress_content=progress_content,
            git_history=git_history,
            init_sh=init_sh_content,
            feature_list=feature_list,
        )
        task_prompt = prompt_loader.get_coding_prompt(
            progress_summary=session_context,
            pending_features=self._format_pending_features(),
            current_task=self._format_current_task(next_feature),
        )

        try:
            self._iteration_count += 1
            result = self._invoke_agent(task_prompt, [])
            output_text = result.get("output", "")

            completion_keywords = ["å®Œæˆ", "completed", "done", "finished", "æˆåŠŸ"]
            lowered = output_text.lower()
            is_completed = any(word in lowered for word in completion_keywords)
            if not output_text.strip():
                is_completed = False

            now_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            if is_completed:
                self.progress_manager.update_feature_status(
                    next_feature.id,
                    "completed",
                    f"å®ŒæˆäºŽ {now_str}",
                )
                summary_title = "## åŠŸèƒ½æ‰§è¡Œè®°å½•ï¼ˆå®Œæˆï¼‰"
            else:
                self.progress_manager.update_feature_status(
                    next_feature.id,
                    "in_progress",
                    f"ä¼šè¯ç»“æŸäºŽ {now_str}ï¼Œéœ€è¦ç»§ç»­æ‰§è¡Œ",
                )
                summary_title = "## åŠŸèƒ½æ‰§è¡Œè®°å½•ï¼ˆè¿›è¡Œä¸­ï¼‰"

            if output_text.strip():
                self.progress_manager.append_to_progress(
                    f"{summary_title}\n\n- åŠŸèƒ½: {next_feature.id} {next_feature.name}\n\n{output_text}"
                )

            if self.git_helper.has_changes():
                if is_completed:
                    commit_msg = f"feat: å®Œæˆ {next_feature.name} ({next_feature.id})"
                else:
                    commit_msg = f"wip: {next_feature.name} è¿›è¡Œä¸­ ({next_feature.id})"
                self.git_helper.commit(commit_msg)

            payload = {
                "success": is_completed,
                "feature_id": next_feature.id,
                "output": output_text,
                "status": "completed" if is_completed else "in_progress",
            }
            if on_iteration is not None:
                on_iteration(self._iteration_count, payload)
            return payload

        except Exception as exc:
            self.progress_manager.update_feature_status(
                next_feature.id,
                "blocked",
                f"é”™è¯¯: {exc}",
            )
            return {"success": False, "error": str(exc), "feature_id": next_feature.id}

    def run_continuous(
        self,
        max_total_iterations: int = 100,
        pause_between_tasks: float = 1.0,
    ) -> Dict[str, Any]:
        """è¿žç»­æ‰§è¡Œä»»åŠ¡ç›´åˆ°å®Œæˆã€é˜»å¡žæˆ–è¾¾åˆ°æœ€å¤§è½®æ¬¡ã€‚"""
        results = {
            "completed_features": [],
            "failed_features": [],
            "total_iterations": 0,
        }

        for _ in range(max_total_iterations):
            next_feature = self.progress_manager.get_next_feature()
            if next_feature is None:
                break

            result = self.run(max_iterations=Config.MAX_ITERATIONS)
            results["total_iterations"] += 1

            feature_id = next_feature.id
            if result.get("success"):
                results["completed_features"].append(feature_id)
            else:
                results["failed_features"].append(feature_id)

            if pause_between_tasks > 0:
                time.sleep(pause_between_tasks)

        return results

    def _build_context(self, progress_content: str, feature_list: Any) -> str:
        """æž„å»ºç®€è¦ä¸Šä¸‹æ–‡æ‘˜è¦ã€‚"""
        stats = self.progress_manager.get_progress_stats()
        context_parts = [
            "## é¡¹ç›®ä¿¡æ¯",
            f"- åç§°: {feature_list.project_name}",
            f"- æ€»åŠŸèƒ½æ•°: {stats['total']}",
            f"- å·²å®Œæˆ: {stats['completed']}",
            f"- å®ŒæˆçŽ‡: {stats['completion_rate']}%",
            "",
            "## å½“å‰è¿›åº¦",
            progress_content or "ï¼ˆæ— è¿›åº¦è®°å½•ï¼‰",
        ]
        return "\n".join(context_parts)

    def _format_pending_features(self) -> str:
        """æ ¼å¼åŒ–å¾…å¤„ç†åŠŸèƒ½åˆ—è¡¨ä¾›æç¤ºè¯ä½¿ç”¨ã€‚"""
        pending = self.progress_manager.get_pending_features()
        if not pending:
            return "ï¼ˆæ— å¾…å®ŒæˆåŠŸèƒ½ï¼‰"

        status_map = {
            "pending": "â³",
            "in_progress": "ðŸ”„",
            "completed": "âœ…",
            "blocked": "âŒ",
        }
        priority_map = {"high": "é«˜", "medium": "ä¸­", "low": "ä½Ž"}

        lines: List[str] = []
        for feature in pending:
            status_icon = status_map.get(feature.status, "â“")
            priority = priority_map.get(feature.priority, "ä¸­")
            lines.append(
                f"{status_icon} [{feature.id}] {feature.name} "
                f"(ä¼˜å…ˆçº§: {priority}, çŠ¶æ€: {feature.status})"
            )

        return "\n".join(lines)

    def _build_session_context(
        self,
        progress_content: str,
        git_history: str,
        init_sh: str,
        feature_list: Any,
    ) -> str:
        """æž„å»ºåŒ…å«è¿›åº¦ã€Git åŽ†å²å’Œå¯åŠ¨è„šæœ¬çš„ä¼šè¯ä¸Šä¸‹æ–‡ã€‚"""
        stats = self.progress_manager.get_progress_stats()
        context_parts = [
            "## ä¼šè¯ä¸Šä¸‹æ–‡",
            "",
            "### é¡¹ç›®ä¿¡æ¯",
            f"- åç§°: {feature_list.project_name}",
            f"- æŠ€æœ¯æ ˆ: {feature_list.tech_stack or 'æœªæŒ‡å®š'}",
            f"- å¯åŠ¨å‘½ä»¤: {feature_list.init_command}",
            f"- æ€»åŠŸèƒ½æ•°: {stats['total']}",
            f"- å·²å®Œæˆ: {stats['completed']}",
            f"- å®ŒæˆçŽ‡: {stats['completion_rate']}%",
            "",
            "### è¿›åº¦æ–‡ä»¶å†…å®¹",
            progress_content or "ï¼ˆæ— è¿›åº¦è®°å½•ï¼‰",
            "",
            git_history,
        ]

        if init_sh:
            context_parts.extend(["", "### init.sh å†…å®¹", "```bash", init_sh, "```"])

        return "\n".join(context_parts)

    def _format_current_task(self, feature: Feature) -> str:
        """æ ¼å¼åŒ–å½“å‰æ‰§è¡Œä»»åŠ¡çš„æè¿°æ–‡æœ¬ã€‚"""
        lines = [
            f"## å½“å‰ä»»åŠ¡: [{feature.id}] {feature.name}",
            "",
            f"**æè¿°**: {feature.description or 'æ— æè¿°'}",
            "",
        ]

        if feature.acceptance_criteria:
            lines.append("**éªŒæ”¶æ ‡å‡†**:")
            for index, criteria in enumerate(feature.acceptance_criteria, 1):
                lines.append(f"{index}. {criteria}")
            lines.append("")

        if feature.test_command:
            lines.append(f"**æµ‹è¯•å‘½ä»¤**: `{feature.test_command}`")
            lines.append("")

        lines.extend(
            [
                "**é‡è¦æé†’**:",
                "- å®ŒæˆåŠŸèƒ½åŽè¿è¡Œæµ‹è¯•å¹¶æ›´æ–°çŠ¶æ€",
                "- ç¡®è®¤ç¬¦åˆéªŒæ”¶æ ‡å‡†åŽå†æ ‡è®° completed",
                "- ä¼šè¯ç»“æŸå‰è®°å½•è¿›åº¦å¹¶åˆ›å»ºæäº¤",
            ]
        )
        return "\n".join(lines)

    def get_status(self) -> Dict[str, Any]:
        """è¿”å›žå½“å‰ Agent çŠ¶æ€ã€ç»Ÿè®¡ä¿¡æ¯ä¸Žä¸‹ä¸€ä»»åŠ¡ã€‚"""
        feature_list = self.progress_manager.load_feature_list(force_reload=True)
        stats = self.progress_manager.get_progress_stats()
        next_feature = self.progress_manager.get_next_feature()

        return {
            "project_dir": self.project_dir,
            "model": self.model_name,
            "project_name": feature_list.project_name if feature_list else "æœªçŸ¥",
            "stats": stats,
            "next_feature": (
                {
                    "id": next_feature.id,
                    "name": next_feature.name,
                    "status": next_feature.status,
                }
                if next_feature
                else None
            ),
            "progress_report": self.progress_manager.get_progress_report(),
        }

    def chat(self, message: str, chat_history: Optional[List[Any]] = None) -> str:
        """æ‰§è¡Œä¸€æ¬¡å¯¹è¯è¯·æ±‚å¹¶è¿”å›žæ–‡æœ¬å›žå¤ã€‚"""
        result = self._invoke_agent(message, chat_history or [])
        return result.get("output", "")

    def add_feature(
        self,
        feature_id: str,
        name: str,
        description: str = "",
        priority: str = "medium",
        dependencies: Optional[List[str]] = None,
    ) -> bool:
        """å‘åŠŸèƒ½åˆ—è¡¨æ·»åŠ æ–°åŠŸèƒ½é¡¹ã€‚"""
        return self.progress_manager.add_feature(
            feature_id=feature_id,
            name=name,
            description=description,
            priority=priority,
            dependencies=dependencies,
        )

    def reset_feature(self, feature_id: str) -> bool:
        """å°†æŒ‡å®šåŠŸèƒ½çŠ¶æ€é‡ç½®ä¸º pendingã€‚"""
        return self.progress_manager.update_feature_status(
            feature_id=feature_id,
            status="pending",
            notes="çŠ¶æ€å·²é‡ç½®",
        )


def create_agent(
    project_dir: str,
    model_name: Optional[str] = None,
    base_url: Optional[str] = None,
) -> CodingAgent:
    """åˆ›å»º CodingAgent å®žä¾‹çš„å·¥åŽ‚å‡½æ•°ã€‚"""
    return CodingAgent(project_dir=project_dir, model_name=model_name, base_url=base_url)


def quick_init(project_dir: str, requirements: str) -> CodingAgent:
    """å¿«é€Ÿå®Œæˆ Agent åˆ›å»ºä¸Žé¡¹ç›®åˆå§‹åŒ–ã€‚"""
    agent = CodingAgent(project_dir)
    agent.initialize(requirements)
    return agent


def quick_run(project_dir: str) -> Dict[str, Any]:
    """å¿«é€Ÿåˆ›å»º Agent å¹¶æ‰§è¡Œä¸€æ¬¡ä»»åŠ¡å¾ªçŽ¯ã€‚"""
    agent = CodingAgent(project_dir)
    return agent.run()
